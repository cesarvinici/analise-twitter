---
title: "Insights Twitter"
author: "Cesar Vinicius <cesarvinici@gmail.com>"
date: "24/11/2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy = FALSE, tidy.opts = list(comment = FALSE))
```
```{r fig.keep='all', message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE, results='hide'}
knitr::opts_chunk$set(tidy = TRUE, tidy.opts = list(comment = FALSE))
setwd("~/Documents/analise-twitter")

#install.packages("mongolite")
#install.packages("abjutils")
#install.packages("wordcloud")
#install.packages("wesanderson") # Paleta de cores
#install.packages("RColorBrewer")
# install.packages("rmarkdown")


library(mongolite)
library(stringr)
library(tibble)
library(tm)
library(abjutils)
library(tidytext)
library(dplyr)
library(readr)
library(wordcloud)
library(wesanderson)
library(tidyr)
library(ggplot2)
library(igraph)
library(ggraph)
library(RColorBrewer)


# Conecting to mongoDB
m <- mongo(url = "mongodb://192.168.16.3/", options = ssl_options(weak_cert_validation = T), db="twitter", collection="tweets_lula")

#Getting tweets from database and saving on R variable
tweets <- m$find(
  fields = '{"_id": false, "text": true}',
)

# stop words
stop_words <- read_delim("stopwords.csv", ";", escape_double = FALSE, trim_ws = TRUE)
stop_words <- add_row(stop_words, word = "to")
stop_words <- add_row(stop_words, word = "tô")
stop_words <- add_row(stop_words, word = "ta")
stop_words <- add_row(stop_words, word = "tá")
stop_words <- add_row(stop_words, word = "q")
stop_words <- add_row(stop_words, word = "pq")
stop_words <- add_row(stop_words, word = "ah")
stop_words <- add_row(stop_words, word = "ai")
stop_words <- add_row(stop_words, word = "s")
stop_words <- add_row(stop_words, word = "x")
stop_words <- add_row(stop_words, word = "tt")
stop_words <- add_row(stop_words, word = "tto")
stop_words <- add_row(stop_words, word = "tts")
stop_words <- add_row(stop_words, word = "vc")
stop_words <- add_row(stop_words, word = "2155")
stop_words <- add_row(stop_words, word = "msm")
stop_words <- add_row(stop_words, word = "mto")
stop_words <- add_row(stop_words, word = "oq")
stop_words <- add_row(stop_words, word = "p")
stop_words <- add_row(stop_words, word = "811")
stop_words <- add_row(stop_words, word = "vai")
stop_words <- add_row(stop_words, word = "vem")
stop_words <- add_row(stop_words, word = "sei")
stop_words <- add_row(stop_words, word = "sai")
stop_words <- add_row(stop_words, word = "fala")
stop_words <- add_row(stop_words, word = "fez")
stop_words <- add_row(stop_words, word = "pode")
stop_words <- add_row(stop_words, word = "agr")
stop_words <- add_row(stop_words, word = "falar")
stop_words <- add_row(stop_words, word = "não")
stop_words <- add_row(stop_words, word = "vão")
stop_words <- add_row(stop_words, word = "vou")
stop_words <- add_row(stop_words, word = "dois")
stop_words <- add_row(stop_words, word = "quer")
stop_words <- add_row(stop_words, word = "né")
stop_words <- add_row(stop_words, word = "ver")
stop_words <- add_row(stop_words, word = "viu")
stop_words <- add_row(stop_words, word = "nao")
stop_words <- add_row(stop_words, word = "leon")
stop_words <- add_row(stop_words, word = "K k")
stop_words <- add_row(stop_words, word = "dia")
stop_words <- add_row(stop_words, word = "ficar")
stop_words <- add_row(stop_words, word = "quero")
stop_words <- add_row(stop_words, word = "hj")
stop_words <- add_row(stop_words, word = "faz")
stop_words <- add_row(stop_words, word = "coisa")
stop_words <- add_row(stop_words, word = "dia")
stop_words <- add_row(stop_words, word = "fazer")
stop_words <- add_row(stop_words, word = "perfil")
stop_words <- add_row(stop_words, word = "cara")
stop_words <- add_row(stop_words, word = "acho")
stop_words <- add_row(stop_words, word = "bom")
stop_words <- add_row(stop_words, word = "c")
stop_words <- add_row(stop_words, word = "dar")
stop_words <- add_row(stop_words, word = "k")
stop_words <- add_row(stop_words, word = "eh")
stop_words <- add_row(stop_words, word = "vcs")
stop_words <- add_row(stop_words, word = "cu")

# stop_words <- add_row(stop_words, word = "kk")
# stop_words <- add_row(stop_words, word = "kkk")
# stop_words <- add_row(stop_words, word = "kkkk")
# stop_words <- add_row(stop_words, word = "kkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkkkkkk")
# stop_words <- add_row(stop_words, word = "kkkkkkkkkkkk")

# Removing urls
patternRegexUrl <- 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'
tweets$text <- str_replace(tweets$text, patternRegexUrl, "") 
patternRegexKs <- 'k{2,}'
tweets$text <- str_replace(tweets$text, patternRegexKs, "")

# Removing @users reference from text
tweets$text <- str_replace_all(tweets$text,  "@\\w+", "") %>%
              removePunctuation() %>% # REMOVE PONTUAÇÃO
              stripWhitespace() # REMOVE ESPAÇOS EM BRANCO E PALAVRAS ACENTUADAS

# Removing emojis
# tweets$text <- gsub("[^\x01-\x7F]", "", tweets$text)

# SEPARA POR PARLAVRA E REMOVE AS STOPWORDS
tokens_tweets <- tweets %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tokens_tweets$word = str_replace_all(tokens_tweets$word, " ", "")
  
# CONTA AS PALAVRAS
tokens_tweets_count <- tokens_tweets %>%
  count(word, sort = TRUE)

#Aumenta a paleta de cores
nb.cols <- 20
mycolors <- colorRampPalette(brewer.pal(8, "Set2"))(nb.cols)
```

### Analise de mensagens no twitter no dia 08/11/2019

Vamos (tentar) analisar alguns tweets gerados no dia 08/11/2019 e ver qual insights podemos tirar de lá.

Antes que me perguntem, **porque dia 08/11/2019?**
  
- Bom, imaginei que usuários de do twitter estariam pavorosos pois foi o dia que o ex presidente Lula foi solto da prisão após a decisao sobre prisões em segunda instância do STF.

Isso dito acredito que um *disclaimer* seja necessário. Bem sabemos que política é um assunto um tanto perigoso para se tratar no Brasil nos últimos tempos, pois de modo geral as pessoas estão cada vez mais polarizadas. Com isso minha intenção aqui é ser o mais imparcial possível.

Três pesquisas foram realizadas no twitter neste dia, usei as *keywords* **Lula** e **Bolsonaro** e uma terceira pesquisa sem uma *keyword* definida, de forma a pegar tudo possível.

Como uso uma versão gratuita da API do twitter, a pesquisa foi um tanto limitada, consegui apenas 4/5 mil tweets em cada pesquisa. Mas acredito que já de pra tirar uns *insights* interessantes!


Para realizar este trabalho foi usado Python para coleta e salvamento dos dados em um container docker rodando um MongoDB e R para as analises.

Todo código está disponível no [Github](https://github.com/cesarvinici)

### Lula

Vamos primeiro para análise utilizando a *keyword* 'Lula':

- Abaixo uma *WordCloud* com as palavras que mais aparecem na pesquisa: 

```{r pressure, echo=FALSE, fig.cap="WordCloud Keyword Lula", out.width = '85%'}
wordcloud(tokens_tweets_count$word, 
          tokens_tweets_count$n, 
          max.words =50, 
          scale = c(4,1.5),
          rot.per=0.1,
          color=mycolors)
```


\s Algumas palavras já imaginavámos que iriam aparecer, como "Lula", "Livre" e afins. Percebemos que a palavra 'Bolsonaro' também aparece com uma boa frequência. É possível verificar que algumas pessoas não ficaram muito feliz com a decisão pois as palavras "ladrão" e "bandido" aparecem. Algumas provocações foram feitas para eleitores do Bolsonaro, já que a palavra comumente usada "Bolsominion" também aparece com certa frequência.

Para confirmar algumas previsões, vamos ver um gráfico de barras mostrando a contagem das palavras:

```{r echo=FALSE, fig.cap="WordCloud Keyword Lula", out.width = '90%'}
# Plotando palavras mais usadas
tokens_tweets_count %>%
  mutate(word = reorder(word,n)) %>%
  filter(word != "lula") %>%
  head(10) %>%
  ggplot(aes(word,n,fill=factor(word)))+
  scale_fill_manual(values = mycolors)+
  geom_col()+
   xlab("Palavras")+
  ylab("Quantidade") +
    coord_flip()
```

*ps*: Como a pesquisa no twitter foi realizada usando a palavra-chave "Lula", não faz sentido plotar ela, já que ela vai aparecer em todos os 4.5 mil tweets.

Nenhuma surpresa quando as palavras "livre" (Lula livre) ou solto, Bolsonaro está no top 3 o que pode ser surpreendente e ao mesmo tempo levar à indagação se são eleitores do Bolsonaro ou eleitores do Lula que estão preocupados com o canditado do outro lado do polo?

Beleza, já sabemos quais foram as palavras que mais se repitiram, mas e as frases? Bigramas, Trigramas e etc? é possível saber? 
\s ***yes it is!**

Vamos aos bigramas (se você não sabe o que é um bigrama [Clique aqui](https://en.wikipedia.org/wiki/Bigram))

```{r echo=FALSE}
# CRIANDO UM BIGRAMA
bigrams <- tweets %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% # Separa as palavras de 2 em 2
  separate(bigram,c("word1","word2"),sep = " ") %>% # Divide entre palavra 1 e palavra 2
  filter(!word1 %in% as.vector(t(stop_words$word))) %>%
  filter(!word2 %in% as.vector(t(stop_words$word))) %>% # Filtra as palavras a partir das stop_words
  unite(bigram,word1,word2,sep = " ") %>%
  count(bigram, sort = TRUE)

bigrams %>%
  mutate(bigram = reorder(bigram,n)) %>%
  head(20) %>%
  ggplot(aes(bigram,n,fill=factor(bigram)))+
  scale_fill_manual(values = mycolors)+
  geom_col()+
  ylab("Quantidade")+
  xlab("Bigrama") +
  coord_flip()
```

Bom, pra surpresa de ninguém o bigrama mais falado foi "Lula livre", e de modo geral com excessão de Boa noite e jornal nacional todas as outras frases foram em um sentido de comemoração à solturado Ex Presidente.

E frases com 3 ou mais palavras? 

```{r echo=FALSE}
trigrams <- tweets %>%
  unnest_tokens(trigrams, text, token = "ngrams", n = 3) %>% # Separa as palavras de 2 em 2
  separate(trigrams,c("word1","word2", "word3"),sep = " ") %>% # Divide entre palavra 1 e palavra 2
  filter(!word1 %in% as.vector(t(stop_words$word))) %>%
  #filter(!word2 %in% as.vector(t(stopwords_pt$word))) %>% # Filtra as palavras a partir das stop_words
  filter(!word3 %in% as.vector(t(stop_words$word))) %>%
  unite(trigrams,word1,word2, word3,sep = " ") %>%
  count(trigrams, sort = TRUE)

trigrams %>%
  mutate(trigrams = reorder(trigrams,n)) %>%
  head(9) %>%
  ggplot(aes(trigrams,n,fill=factor(trigrams)))+
  scale_fill_manual(values = mycolors) +
  geom_col()+
  coord_flip()

# CREATE TRIGAMS
quadrams <- tweets %>%
  unnest_tokens(quadrams, text, token = "ngrams", n = 4) %>% # Separa as palavras de 2 em 2
  separate(quadrams,c("word1","word2", "word3", "word4"),sep = " ") %>% # Divide entre palavra 1 e palavra 2
  filter(!word1 %in% as.vector(t(stop_words$word))) %>%
  #filter(!word2 %in% as.vector(t(stopwords_pt$word))) %>% # Filtra as palavras a partir das stop_words
  filter(!word4 %in% as.vector(t(stop_words$word))) %>%
  unite(quadrams,word1,word2, word3, word4,sep = " ") %>%
  count(quadrams, sort = TRUE)

quadrams %>%
  mutate(quadrams = reorder(quadrams,n)) %>%
  head(9) %>%
  ggplot(aes(quadrams,n,fill=factor(quadrams)))+
  scale_fill_manual(values = mycolors) +
  geom_col()+
  coord_flip()
```

Via de regra são pessoas ou comemorando ou, ao que parece simplemente comentando a soltura.

Bom, se formos analisar friamente não obtivemos nenhuma grande surpresa nas palavras nem nas frases ditas pelos usuários do Twitter ao que se refere ao Lula, mas e em uma analise de sentimentos, será que eles se portaram de forma mais agressiva ou mais positiva? 

Vamos analisar! 









